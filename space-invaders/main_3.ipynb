{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "from collections import deque\n",
    "from typing import Deque, Dict, List, Tuple\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pygame as pygame\n",
    "import numpy as np\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "import gc\n",
    "import json\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
    "XRES = 800\n",
    "YRES = 600\n",
    "FACTOR = 8\n",
    "XRES_SCALED = int(XRES / FACTOR)\n",
    "YRES_SCALED = int(YRES / FACTOR)\n",
    "TICKS_REF = 80\n",
    "ACTION_SIZE = 4\n",
    "FRAME_SKIP = 3\n",
    "SCREEN = pygame.display.set_mode((XRES, YRES))\n",
    "STATS_FILE = 'stats_RANDOM.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from game_v2 import SpaceInvaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, action_size):\n",
    "        self.action_size = action_size\n",
    "        self.frame_skip = FRAME_SKIP\n",
    "        self.epsilon = 1.0\n",
    "\n",
    "    def act(self, state):\n",
    "        return random.randrange(self.action_size)\n",
    "\n",
    "    def play(self, game, episode, max_episodes=1000, stats=None):\n",
    "        # Retrieve action to play\n",
    "        state = game.get_state()\n",
    "        action = self.act(state)\n",
    "\n",
    "        # Step game with frame skipping\n",
    "        reward = 0\n",
    "        for _ in range(self.frame_skip):\n",
    "            next_state, r, done = game.step(action=action)\n",
    "            reward += r\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        if stats is not None:\n",
    "            stats['rewards'].append(reward)\n",
    "        if done:\n",
    "            if stats is not None:\n",
    "                stats['scores'].append(game.score)\n",
    "                stats['episode'].append(episode)\n",
    "\n",
    "        return done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(ACTION_SIZE)\n",
    "game = SpaceInvaders(SCREEN, agent, XRES_SCALED, YRES_SCALED, TICKS_REF)\n",
    "stats = dict({\n",
    "    'scores': [],\n",
    "    'rewards': [],\n",
    "    'episode': [],\n",
    "})\n",
    "episode_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def update_screen(display_handle, screen, stats, fig, ax):\n",
    "    def batch_mean(x, w):\n",
    "      s_len = len(x) - len(x) % w\n",
    "      s = x[0:s_len]\n",
    "      s_x = np.array(np.array_split(s, len(s) // w, axis=0))\n",
    "      avg = np.mean(s_x, axis=1)\n",
    "      s_len = len(avg)\n",
    "      x_ticks = range(w, (s_len+ 1) * w, w)\n",
    "      return avg, s_len, x_ticks\n",
    "\n",
    "    def running_mean(x, w):\n",
    "      avg = np.convolve(x, np.ones(w), 'valid') / w\n",
    "      s_len = len(avg)\n",
    "      return avg, s_len, range(0, s_len, 1)\n",
    "\n",
    "    view = pygame.surfarray.array3d(screen)\n",
    "\n",
    "    #  convert from (width, height, channel) to (height, width, channel)\n",
    "    scores = np.array(stats['scores'])\n",
    "    view = view.transpose([1, 0, 2])\n",
    "    img_bgr = cv2.cvtColor(view, cv2.COLOR_RGB2BGR)\n",
    "    img_bgr = cv2.putText(img_bgr,\n",
    "        str(np.round(np.mean(scores), decimals=2)) + \"/\" +\n",
    "        str(np.max(scores, initial=0)) + \"/\" +\n",
    "        str(len(scores)) + \"/\" +\n",
    "        str(agent.epsilon),\n",
    "        (0, YRES-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,0,255), 2)\n",
    "    img_bgr = cv2.resize(img_bgr, (500, 400), None)\n",
    "\n",
    "    plot = False\n",
    "    if len(scores) > 100 * 2:\n",
    "        avg, s_len, x_ticks = batch_mean(scores, 100)\n",
    "        plot = True\n",
    "    elif len(scores) > 0:\n",
    "        avg, s_len, x_ticks = running_mean(scores, 10)\n",
    "        plot = True\n",
    "    \n",
    "    if plot:\n",
    "        z = np.zeros_like(avg)\n",
    "        if len(avg) > 1:\n",
    "            z = np.polyfit(range(s_len), avg, 1)\n",
    "        p = np.poly1d(z)\n",
    "\n",
    "        ax.plot(x_ticks, avg)\n",
    "        ax.plot(x_ticks, p(range(s_len)))\n",
    "\n",
    "    fig.suptitle(\"Average Score\")\n",
    "\n",
    "    # convert canvas to image\n",
    "    fig.canvas.draw()\n",
    "    fig.canvas.flush_events()\n",
    "    img_sts = np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep='')\n",
    "    img_sts = img_sts.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    ax.cla()\n",
    "\n",
    "    # img is rgb, convert to opencv's default bgr\n",
    "    img_sts = cv2.cvtColor(img_sts, cv2.COLOR_RGB2BGR)\n",
    "    img_sts = cv2.resize(img_sts, (500, 400), None)\n",
    "    img = np.hstack((img_bgr, img_sts))\n",
    "    ret, img_data = cv2.imencode(\".jpg\", img)\n",
    "    assert ret\n",
    "    clear_output(wait=True)\n",
    "    display_handle.display(Image(data=img_data.tobytes()))\n",
    "    del img_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_game(game, agent, stats=None, episodes=-1, train=True, display_res=10, display_fig=True):\n",
    "    display_handle = display(None, display_id=True)\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    plt.ion()\n",
    "\n",
    "    display_cnt = 0\n",
    "    episode = 0\n",
    "    agent.training = train\n",
    "    while episode <= episodes:\n",
    "        episode += 1\n",
    "        game.reset(0)\n",
    "        game.start()\n",
    "        done = False\n",
    "        while not done:\n",
    "            done = agent.play(game, episode, stats=stats)\n",
    "            display_cnt += 1\n",
    "            if display_fig and (done or display_cnt % display_res == 0):\n",
    "                asyncio.run(update_screen(display_handle, SCREEN, stats, fig, ax))\n",
    "\n",
    "        # Save model and stats if needed\n",
    "        if stats is not None:\n",
    "            with open(STATS_FILE, 'w') as fout:\n",
    "                json.dump(stats, fout)\n",
    "\n",
    "        # Cleanup memory\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To restore saved state\n",
    "if os.path.exists(STATS_FILE):\n",
    "    with open(STATS_FILE, \"r\") as f:\n",
    "        stats = json.load(f)\n",
    "    print(\"restoring stats to: \" + STATS_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Training\n",
    "run_game(game, agent, stats=stats, episodes=5000, train=True, display_res=20, display_fig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Visualizing\n",
    "run_game(game, agent, stats=None, episodes=5, train=False, display_res=1, display_fig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title: Deep Reinforcement Learning to play Space Invaders\n",
    "Link: https://nihit.github.io/resources/spaceinvaders.pdf\n",
    "Type: Paper\n",
    "\n",
    "Title: Frame Skipping and Pre-Processing for Deep Q-Networks on Atari 2600 Games\n",
    "Link: https://danieltakeshi.github.io/2016/11/25/frame-skipping-and-preprocessing-for-deep-q-networks-on-atari-2600-games/\n",
    "Type: Blog Post\n",
    "\n",
    "Title: GuarDiqN: Playing Space Invader with Dueling Double Deep Q-Network\n",
    "Link: https://github.com/lychengrex/Playing-Space-Invaders-with-Deep-Q-Networks/tree/master\n",
    "Type: Source Code\n",
    "\n",
    "Title: Improving the DQN algorithm using Double Q-Learning\n",
    "Link: https://davidrpugh.github.io/stochastic-expatriate-descent/pytorch/deep-reinforcement-learning/deep-q-networks/2020/04/11/double-dqn.html\n",
    "Type: Blog Post\n",
    "\n",
    "Title: Double Q-learning\n",
    "Link: https://proceedings.neurips.cc/paper_files/paper/2010/file/091d584fced301b442654dd8c23b3fc9-Paper.pdf\n",
    "Type: Paper\n",
    "\n",
    "Title: Deep reinforcement learning with pixel features in Atari Pong Game\n",
    "Link: https://github.com/gznyyb/deep_reinforcement_learning_Pong/tree/master\n",
    "Type: Source Code\n",
    "\n",
    "Title: TRAIN A MARIO-PLAYING RL AGENT\n",
    "Link: https://pytorch.org/tutorials/intermediate/mario_rl_tutorial.html\n",
    "Type: Blog Post\n",
    "\n",
    "Title: Playing Super Mario Bros with Deep Reinforcement Learning\n",
    "Link: https://www.analyticsvidhya.com/blog/2021/06/playing-super-mario-bros-with-deep-reinforcement-learning/\n",
    "Type: Blog Post\n",
    "\n",
    "Title: Deep Reinforcement Learning with Space Invaders… Literally from scratch\n",
    "Link: https://yaassinekaddi.medium.com/deep-reinforcement-learning-with-space-invaders-literally-from-scratch-part-i-10905fe04846\n",
    "Type: Blog Post\n",
    "\n",
    "Title: Asynchronous Methods for Deep Reinforcement Learning\n",
    "Link: https://arxiv.org/pdf/1602.01783.pdf\n",
    "Type: Paper\n",
    "\n",
    "Title: Reinforcement-Learning-Atari-Games\n",
    "Link: https://github.com/NitishMutha/Reinforcement-Learning-Atari-Games/tree/master\n",
    "Type: Source Code\n",
    "\n",
    "Title: Practical Reinforcement Learning — 02 Getting started with Q-learning\n",
    "Link: https://towardsdatascience.com/practical-reinforcement-learning-02-getting-started-with-q-learning-582f63e4acd9\n",
    "Type: Blog Post\n",
    "\n",
    "Title: Playing Atari with Deep Reinforcement Learning\n",
    "Link: https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf\n",
    "Type: Paper\n",
    "\n",
    "Title: RL\n",
    "Link: https://github.com/msachin93/RL\n",
    "Type: Source Code\n",
    "\n",
    "Title: Space Invaders challenge: a Reinforcement Learning competition\n",
    "Link: https://wandb.ai/raghmura/qualcomm/reports/Space-Invaders-challenge-a-Reinforcement-Learning-competition--Vmlldzo5MzEzMg\n",
    "Type: Blog Post"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
